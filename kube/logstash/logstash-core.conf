# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => "my-log"
    group_id => "mygroup"
    tags => ["kafka"]
    auto_offset_reset => "earliest" #"latest"
  }
}

filter {
  json {
    source => "message"
  }

  date {
    match => ["timestamp", "yyyy-MM-dd HH:mm:ss"]
    target => "@timestamp"
    locale => "ko"
    timezone => "Asia/Seoul"
  }

  geoip {
    source => "host_address"
  }

  mutate {
    add_field => {
        # location mapping is geo_point 
        "[location][lon]" => "%{[geoip][longitude]}"
        "[location][lat]" => "%{[geoip][latitude]}"
        "country" => "%{[geoip][country_name]}"
        "zone" => "%{[geoip][timezone]}"
        # "location1" => ["%{[geoip][longitude]}", "%{[geoip][latitude]}"]
    }
  }

  mutate {
    copy => {"url" => "_url"}
  }

  mutate {
    split => {"_url" => "/"}
  }

  if "_geoip_lookup_failure" in [tags] {
    mutate {
        update => {
            "country" => "N/A"
            "city" => "N/A"
            "zone" => "N/A"
            "[location][lon]" => "0"
            "[location][lat]" => "0"
        }
    }
  }

  mutate {
    convert => {
        "[location][lon]" => "float"
        "[location][lat]" => "float"
    }
  }

  mutate {
    add_field => {
        "domain" => "%{[_url][2]}"
    }
    remove_field => ["message", "_url", "geoip", "timestamp"]
  }
}

output {
  if "kafka" in [tags] {
    # stdout {
    #     codec => json
    # }

    elasticsearch {
      hosts => ["elastic-0.elastic.default:9200", "elastic-1.elastic.default:9200", "elastic-2.elastic.default:9200"]
      index => "es7-weblog2"
    }
  }
}
